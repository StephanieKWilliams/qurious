ğŸ’¬ Qurious â€“ Frontend for LLM-Powered Conversations

A sleek, modern frontend for real-time AI chat â€” built with Next.js 15 App Router, Tailwind CSS, and Framer Motion. Connects to a FastAPI backend that delivers responses via Groq's ultra-fast inference API.
âœ¨ Features

    ğŸ§  Real-Time Chat â€” Typing indicators and instant LLM responses

    ğŸ¨ Animated UI â€” Smooth transitions with Framer Motion

    ğŸ’¾ Chat History â€” Stored in localStorage, session-based memory

    ğŸŒ Backend Configurable â€” Environment-based API URL

    ğŸ“± Responsive Design â€” Works seamlessly on all devices

    âœ… Error Feedback â€” Built-in toasts for success/failure

ğŸ”§ Tech Stack

    Next.js 15 â€” App Router + Server Actions

    React 19

    TypeScript

    Tailwind CSS

    Framer Motion

    Radix UI (for accessible components)

    Lucide Icons

    Zustand (for global state management)

ğŸš€ Getting Started
1. Clone & Install

git clone <frontend-repo-url>
cd qurious

# Install dependencies
npm install

2. Set Up Environment

Create a .env.local file at the root:

NEXT_PUBLIC_API_URL=https://your-backend-service-url.com

    Use your deployed FastAPI backend URL (e.g. Railway, Fly.io, or Render).

3. Run Locally

npm run dev

Then open:

http://localhost:3000
